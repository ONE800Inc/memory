{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the test for memory using Langchain and other libraries \n",
    "\n",
    "For now, here will be focused on only the short term and long term memories using Langchain. Knowdledge based memories will be explored in the later version \n",
    "\n",
    "Also note that the python environment it is currently running is Python3.11"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Langchain "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of different memories: \n",
    "- ConversationBufferMemory\n",
    "- ConversationSummaryMemory\n",
    "- ConversationBufferWindowMemory\n",
    "- ConversationSummaryBufferMemory\n",
    "- Conversation Knowledge Graph Memory \n",
    "- Entity Memory \n",
    "- Custom Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 -q install openai langchain huggingface_hub transformers "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Memory commands: \n",
    "\n",
    "1. Conversation Buffer Memory -- most basic memory; consist of humand and AI original conversation \n",
    "\n",
    "```python\n",
    "memory = ConversationBufferMemory()\n",
    "```\n",
    "\n",
    "2. Conversation Summary Memory \n",
    "``` python \n",
    "summary_memory = ConversationSummaryMemory(llm = OpenAI())\n",
    "``` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Conversation with ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in deps \n",
    "\n",
    "import os \n",
    "from langchain_testings.apikey import API_KEY\n",
    "\n",
    "import streamlit as st \n",
    "from langchain.llms import OpenAI \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    "st.title('Youtube GPT Creator')\n",
    "prompt = st.text_input('plug in your prompt here ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory \n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name = 'text-davinci-003',\n",
    "             temperature = 0.8,\n",
    "             max_tokens = 256)\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    verbose = True,\n",
    "    memory = memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Jerry Cheng\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hi Jerry, my name is AI. Nice to meet you. What can I help you with?'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Hi, my name is Jerry Cheng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Jerry Cheng\n",
      "AI:  Hi Jerry, my name is AI. Nice to meet you. What can I help you with?\n",
      "Human: My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Congratulations on having a one-year-old GoldenDoodle, Jerry! GoldenDoodles, as a breed, are known to be intelligent, energetic, and loving. At this age, it is important to provide your pup with proper nutrition, exercise, and mental stimulation. Additionally, it is important to socialize him with different people, animals, and environments to ensure he is comfortable in all situations. If you have any questions or need more advice, there are many resources available.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Jerry Cheng\n",
      "AI:  Hi Jerry, my name is AI. Nice to meet you. What can I help you with?\n",
      "Human: My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \n",
      "AI:  Congratulations on having a one-year-old GoldenDoodle, Jerry! GoldenDoodles, as a breed, are known to be intelligent, energetic, and loving. At this age, it is important to provide your pup with proper nutrition, exercise, and mental stimulation. Additionally, it is important to socialize him with different people, animals, and environments to ensure he is comfortable in all situations. If you have any questions or need more advice, there are many resources available.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Conversation with ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name = 'text-davinci-003',\n",
    "             temperature = 0.8,\n",
    "             max_tokens = 256)\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm = OpenAI())\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    verbose = True,\n",
    "    memory = summary_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi my name is Jerry Cheng\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The AI introduces itself as AIbot and greets the human, Jerry Cheng. It asks him what it can help him with.\n",
      "Human: My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The AI introduces itself as AIbot and greets the human, Jerry Cheng. It asks him what it can help him with. The human responds by asking what he should be aware of when having a one-year-old GoldenDoodle. The AI responds that GoldenDoodles need lots of exercise, socializing, and positive reinforcement training, and they are prone to separation anxiety, so it is important to create a consistent routine with them. It also suggests consulting a veterinarian or qualified animal behaviorist if any concerns arise.\n",
      "Human: when is my dogs birtherday \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, Jerry, I don't know the answer to that question. Would you like me to help you find out?\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Hi my name is Jerry Cheng\")\n",
    "conversation.predict(input = \"My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \")\n",
    "conversation.predict(input = 'when is my dogs birtherday ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The AI introduces itself as AIbot and greets the human, Jerry Cheng. It asks him what it can help him with. The human responds by asking what he should be aware of when having a one-year-old GoldenDoodle. The AI responds that GoldenDoodles need lots of exercise, socializing, and positive reinforcement training, and they are prone to separation anxiety, so it is important to create a consistent routine with them. It also suggests consulting a veterinarian or qualified animal behaviorist if any concerns arise. The human then asks when his dog's birthday is, to which the AI responds that it doesn't know the answer, but offers to help him find out.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer) # problem here -- losing useful information "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic conversation with ConversationBufferWindowMemory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name = 'text-davinci-003',\n",
    "             temperature = 0.8,\n",
    "             max_tokens = 256)\n",
    "\n",
    "window_memory = ConversationBufferWindowMemory(k = 2)\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm = llm,\n",
    "    verbose = True,\n",
    "    memory = window_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The AI introduces itself as AIbot and greets the human, Jerry Cheng. It asks him what it can help him with. The human responds by asking what he should be aware of when having a one-year-old GoldenDoodle. The AI responds that GoldenDoodles need lots of exercise, socializing, and positive reinforcement training, and they are prone to separation anxiety, so it is important to create a consistent routine with them. It also suggests consulting a veterinarian or qualified animal behaviorist if any concerns arise. The human then asks when his dog's birthday is, to which the AI responds that it doesn't know the answer, but offers to help him find out.\n",
      "Human: Hi my name is Jerry Cheng\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The AI introduces itself as AIbot and greets the human, Jerry Cheng. It asks him what it can help him with. The human responds by asking what he should be aware of when having a one-year-old GoldenDoodle. The AI responds that GoldenDoodles need lots of exercise, socializing, and positive reinforcement training, and they are prone to separation anxiety, so it is important to create a consistent routine with them. It also suggests consulting a veterinarian or qualified animal behaviorist if any concerns arise.\n",
      "Human: My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The AI introduces itself as AIbot and greets the human, Jerry Cheng. It asks him what it can help him with, and the human responds by asking what he should be aware of when having a one-year-old GoldenDoodle. The AI responds that GoldenDoodles need lots of exercise, socializing, and positive reinforcement training, and they are prone to separation anxiety, so it is important to create a consistent routine with them. It also suggests consulting a veterinarian or qualified animal behaviorist if any concerns arise. Additionally, it congratulated the human, Jerry Cheng, on having his one-year-old GoldenDoodle, Charlie, whose birthday is on June 10th.\n",
      "Human: when is my dogs birtherday \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Your dog, Charlie, has a birthday on June 10th. Congratulations!'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Hi my name is Jerry Cheng\")\n",
    "conversation.predict(input = \"My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \")\n",
    "conversation.predict(input = 'when is my dogs birtherday ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(conversation_with_summary.memory.buffer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Conversation with ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name='text-davinci-003', \n",
    "             temperature=0, \n",
    "             max_tokens = 512)\n",
    "\n",
    "# Setting k=2, will only keep the last 2 interactions in memory\n",
    "# max_token_limit=40 - token limits needs transformers installed\n",
    "memory = ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=40) \n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory=memory, \n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi my name is Jerry Cheng\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Jerry Cheng\n",
      "AI:  Hi Jerry Cheng, my name is AI. It's nice to meet you. What brings you here today?\n",
      "Human: My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human introduces himself to the AI and mentions his one-year-old GoldenDoodle, Charlie. The AI congratulates him and explains that it's important to continue socializing and exposing the dog to new people, places, and experiences. The AI also recommends providing the dog with plenty of mental and physical stimulation along with positive reinforcement when he does something right.\n",
      "Human: My dad is called wei cheng, my mum is called ning zhang. they live in china\n",
      "AI:\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "conversation_with_summary.predict(input = \"Hi my name is Jerry Cheng\")\n",
    "conversation_with_summary.predict(input = \"My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \")\n",
    "conversation_with_summary.predict(input = 'My dad is called wei cheng, my mum is called ning zhang. they live in china')\n",
    "conversation_with_summary.predict(input = 'I have lived in Toronto for six years now. what is the best city to visit in America?')\n",
    "conversation_with_summary.predict(input = 'My dads birthday is on August 1st, and my mum is one Nov, 26th ')\n",
    "conversation_with_summary.predict(input = 'How many days are there in between my dog birthday and my dads birthday? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(conversation_with_summary.memory.buffer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Conversation with Conversation Knowledge Graph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationKGMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name='text-davinci-003', \n",
    "             temperature=0, \n",
    "             max_tokens = 256)\n",
    "\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template\n",
    ")\n",
    "\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    prompt=prompt,\n",
    "    memory=ConversationKGMemory(llm=llm)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: Hi my name is Jerry Cheng\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: I am a mechanical engineering student\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "On Jerry Cheng: Jerry Cheng is a mechanical engineering student.\n",
      "\n",
      "Conversation:\n",
      "Human: i am designing a autonomous commercialized robotic arm that help with household chroses\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' That sounds like an interesting project! Can you tell me more about it? What kind of tasks do you envision the robotic arm performing?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.predict(input = \"Hi my name is Jerry Cheng\")\n",
    "conversation_with_kg.predict(input = \"My dog's name is Charlie, he is one year old and his birthday is on June 10th. what should i be aware of when having a one-year-old GoldenDoodle? \")\n",
    "conversation_with_kg.predict(input = 'My dad is called wei cheng, my mum is called ning zhang. they live in china')\n",
    "conversation_with_kg.predict(input = 'I have lived in Toronto for six years now. what is the best city to visit in America?')\n",
    "conversation_with_kg.predict(input = 'My dads birthday is on August 1st, and my mum is one Nov, 26th ')\n",
    "conversation_with_kg.predict(input = 'How many days are there in between my dog birthday and my dads birthday? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.1-cp311-cp311-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.0.7-cp311-cp311-macosx_11_0_arm64.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.7/229.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.4-cp311-cp311-macosx_11_0_arm64.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jerrycheng/Library/Python/3.11/lib/python/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jerrycheng/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jerrycheng/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.39.4 kiwisolver-1.4.4 matplotlib-3.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain.graphs.networkx_graph.NetworkxEntityGraph object at 0x165ab8650>\n",
      "[('Jerry Cheng', 'Jerry Cheng', 'name is'), ('Jerry Cheng', 'mechanical engineering student', 'is a'), ('Robotic arm', 'help with household chores', 'is designed to'), ('Robotic arm', 'commercialized', 'is autonomous')]\n"
     ]
    }
   ],
   "source": [
    "# NetworkX Entity graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nx.draw(conversation_with_kg.memory.kg, with_labels=True)\n",
    "# plt.show()\n",
    "\n",
    "print(conversation_with_kg.memory.kg)\n",
    "print(conversation_with_kg.memory.kg.get_triples()) # break them into different chains "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Memory \n",
    "\n",
    "Look for specific entities in the conversation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationEntityMemory\n",
    "from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n{entities}\\n\\nCurrent conversation:\\n{history}\\nLast line:\\nHuman: {input}\\nYou:'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The propmpt\n",
    "ENTITY_MEMORY_CONVERSATION_TEMPLATE.template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name='text-davinci-003', \n",
    "             temperature=0, \n",
    "             max_tokens = 256)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Jerry Cheng': ''}\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Last line:\n",
      "Human: Hi my name is Jerry Cheng\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Jerry Cheng': 'Jerry Cheng is a person.', 'Mechanical Engineering': ''}\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Jerry Cheng\n",
      "AI:  Hi Jerry, nice to meet you! How can I help you today?\n",
      "Last line:\n",
      "Human: I am a mechanical engineering student\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Jerry Cheng': 'Jerry Cheng is a person studying mechanical engineering.', 'Mechanical Engineering': 'Mechanical engineering is a field of study focused on the design and construction of machinery.', 'Autonomous': '', 'Commercialized': '', 'Robotic Arm': '', 'Household Chores': ''}\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Jerry Cheng\n",
      "AI:  Hi Jerry, nice to meet you! How can I help you today?\n",
      "Human: I am a mechanical engineering student\n",
      "AI:  Nice to meet you, Jerry! Mechanical engineering is a fascinating field. What are some of the topics you are currently studying?\n",
      "Last line:\n",
      "Human: i am designing a autonomous commercialized robotic arm that help with household chroses\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' That sounds like an interesting project! What challenges have you encountered so far in designing the robotic arm?'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Hi my name is Jerry Cheng\")\n",
    "conversation.predict(input = \"I am a mechanical engineering student\")\n",
    "conversation.predict(input = 'i am designing a autonomous commercialized robotic arm that help with household chroses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jerry Cheng',\n",
       " 'Mechanical Engineering',\n",
       " 'Autonomous',\n",
       " 'Commercialized',\n",
       " 'Robotic Arm',\n",
       " 'Household Chores']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(conversation.memory.store)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Agents with custom search and memories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "python-telegram-bot 20.2 requires httpx~=0.23.3, but you have httpx 0.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain huggingface_hub openai google-search-results tiktoken duckduckgo-search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import streamlit as st \n",
    "from langchain.llms import OpenAI \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.180\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/homebrew/lib/python3.11/site-packages\n",
      "Requires: aiohttp, dataclasses-json, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.tools import DuckDuckGoSearchRun \n",
    "\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which tools the agent can use to answer user queries\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = search.run(\"How can I treat a sprained ankle?\")\n",
    "type(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sprained ankle — Injury to a ligament of the ankle can usually be treated with at-home care and appropriate exercises to get you back on your feet. This content does not have an English version. This content does not have an Arabic version. Skip to content Care at Mayo Clinic Care at Mayo Clinic About Mayo Clinic Request Appointment Find a Doctor Stretching keeps the muscles strong and limber. It also helps more blood circulate to the area, which may help the ankle heal faster. Gently stretch the ankle by moving it in all directions at ... At-home ankle sprain treatments. • Rest: The first step in treating a sprained ankle is to let it rest. Take the weight off it; try not to move it too much and consider crutches if the pain is bad enough. • Ice: Use ice or a cold pack on the affected area. Put some ice in a kitchen towel and place it on your foot for about 30 minutes. Here's how it works: Rest the ankle (use crutches if needed) Ice the ankle for 20 to 30 minutes every 2 to 3 hours for the first 2 days. Compress (wrap) the ankle lightly -- not tightly -- with ... The injury occurs when one or more of the ligaments — elastic bands of tissue that keep the ankle bones in place — are stretched or torn. The most common type of ankle sprain is an inversion injury, or lateral ankle sprain. The foot rolls inward, damaging the ligaments of the outer ankle. Less common are sprains affecting the ligaments of ...\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ice. 3 /12. To curb swelling and pain in the first 24 hours after a minor injury, apply a cold compress for 20-30 minutes. Then remove it for 20-30 minutes. You can use a bag of frozen peas. Or ... Achilles Tendon Injury Symptoms. The most obvious sign is pain above your heel, especially when you stretch your ankle or stand on your toes. It may be mild and get better or worse over time. If ... Symptoms of muscle strain include: Swelling, bruising, or redness due to the injury. Pain at rest. Pain when the specific muscle or the joint in relation to that muscle is used. Weakness of the ... RICE. 2 /14. It stands for rest, ice, compress, and elevate, and it's the go-to treatment for minor sprains and bruising. Ice the injury as soon as possible and put pressure on it with an ... Trauma to an area (jerking movements, auto accidents, falls, fractures, sprains, dislocations, and direct blows to the muscle) also can cause musculoskeletal pain. Other causes of pain include ...\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"site:webmd.com How can I treat a sprained ankle?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duck_wrapper(input_text):\n",
    "    search_results = search.run(f\"site:webmd.com {input_text}\")\n",
    "    return search_results\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search WebMD\",\n",
    "        func=duck_wrapper,\n",
    "        description=\"useful for when you need to answer medical and pharmalogical questions\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template \n",
    "\n",
    "This instructs the agent on what to do. Generally, the template should incorporate:\n",
    "\n",
    "**`tools:`** which tools the agent has access and how and when to call them.\n",
    "\n",
    "**`intermediate_steps:`** These are tuples of previous (**`AgentAction`**, **`Observation`**) pairs. These are generally not passed directly to the model, but the prompt template formats them in a specific way.\n",
    "\n",
    "**`input:`** generic user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Answer the following questions as best you can, but speaking as compasionate medical professional. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to answer as a compansionate medical professional when giving your final answer.\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Output Parser \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2) \n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, \n",
    "                                                    tools=tools, \n",
    "                                                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should figure out what symptoms and treatments are associated with a sprain.\n",
      "Action: Search WebMD\n",
      "Action Input: Sprained ankle\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m3 /12. To curb swelling and pain in the first 24 hours after a minor injury, apply a cold compress for 20-30 minutes. Then remove it for 20-30 minutes. You can use a bag of frozen peas. Or put ice ... Symptoms of muscle strain include: Swelling, bruising, or redness due to the injury. Pain at rest. Pain when the specific muscle or the joint in relation to that muscle is used. Weakness of the ... Achilles Tendon Injury Symptoms. The most obvious sign is pain above your heel, especially when you stretch your ankle or stand on your toes. It may be mild and get better or worse over time. If ... You think a sprain or broken bone may have caused it. It keeps getting bigger after the first day. It makes your arm or leg swollen or tight. Numbness, pins-and-needles, or electricity-like pain in the limb. Swelling, tightness and bruising. Symptoms of chronic compartment syndrome (exertional compartment syndrome) include worsening ...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I now know the treatments and symptoms associated with a sprain.\n",
      "Final Answer: To treat a sprain, you should apply a cold compress for 20-30 minutes, then remove it for 20-30 minutes. You should also look out for symptoms such as swelling, bruising, pain at rest or when the muscle or joint is used, weakness, numbness, pins-and-needles, or electricity-like pain in the limb. If the pain persists or gets worse, you should seek medical attention.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To treat a sprain, you should apply a cold compress for 20-30 minutes, then remove it for 20-30 minutes. You should also look out for symptoms such as swelling, bruising, pain at rest or when the muscle or joint is used, weakness, numbness, pins-and-needles, or electricity-like pain in the limb. If the pain persists or gets worse, you should seek medical attention.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How can I treat a spained ankle?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
